{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "_HHWhmwf3kJB",
   "metadata": {
    "id": "_HHWhmwf3kJB"
   },
   "source": [
    "# **추출 체인(Extraction Chain) 구축하기**\n",
    "\n",
    "이 노트북에서는 **채팅 모델(Chat Models)** 의 **도구 호출(Tool Calling)** 기능을 사용하여 **비정형 텍스트에서 구조화된 정보를 추출**하는 방법을 다룹니다. 또한 이 맥락에서 **Few-Shot 프롬프팅(Few-Shot Prompting)** 을 사용하여 성능을 개선하는 방법을 시연할 것입니다.\n",
    "\n",
    "### 주요 내용\n",
    "- Pydantic을 활용해 데이터 추출을 위한 스키마(Schema) 정의  \n",
    "- LangChain의 Tool Calling 기능을 사용해 LLM이 구조화된 데이터를 반환하도록 설정  \n",
    "- Few-Shot 프롬프팅(Few-Shot Prompting) 기법을 사용해 성능 향상  \n",
    "- 다중 엔터티(Multiple Entity) 추출 지원 (여러 개의 인물 정보 추출 가능)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6b970-2ea3-4192-951e-21237212b359",
   "metadata": {
    "id": "54d6b970-2ea3-4192-951e-21237212b359"
   },
   "source": [
    "## **스키마 (The Schema)**  \n",
    "\n",
    "먼저, 텍스트에서 어떤 정보를 추출할 것인지 **정의**해야 합니다.  \n",
    "\n",
    "이를 위해 **Pydantic**을 사용하여 **개인 정보(personal information)** 를 추출하기 위한 예제 **스키마(schema)** 를 정의할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f98bacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d0aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional  \n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"\n",
    "    사람에 대한 정보.\n",
    "    - 모든 필드는 선택적(optional)입니다.  \n",
    "    - 각 필드는 `description`을 포함하며, LLM이 이를 활용하여 정확한 추출 결과를 생성합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    name: Optional[str] = Field(default=None, description=\"사람의 이름\")\n",
    "    hair_color: Optional[str] = Field(default=None, description=\"사람의 머리 색상\")\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"미터 단위로 측정된 키\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248dd54-e36d-435a-b154-394ab4ed6792",
   "metadata": {
    "id": "f248dd54-e36d-435a-b154-394ab4ed6792"
   },
   "source": [
    "## **스키마 정의의 두 가지 사례**\n",
    "\n",
    "1. **속성(attributes)** 과 **스키마(schema)** 를 Pydantic으로 문서화  \n",
    "   - 이 정보는 LLM에 전달되며, Pydantic 스키마를 통해 명확하게 정의되어 정보 추출의 품질을 개선하는 데 사용됩니다.\n",
    "     \n",
    "<pr></pr>\n",
    "\n",
    "2. **LLM이 정보를 지어내지 않도록 합니다.**  \n",
    "   - 각 속성에 `Optional`을 사용하여 LLM이 답을 모를 경우 `None`을 반환할 수 있도록 했습니다.\n",
    "  \n",
    "최상의 성능을 얻으려면 **스키마를 잘 문서화**하고, 텍스트에 추출할 정보가 없을 경우 모델이 결과를 **강제로 반환하지 않도록** 설정합니다.  \n",
    "\n",
    "\n",
    "## **추출기 (The Extractor)**\n",
    "\n",
    "이제 위에서 정의한 **스키마(schema)** 를 사용하여 **정보 추출기(Information Extractor)** 를 만들어 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4156fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# 사용자 정의 프롬프트 템플릿 정의\n",
    "# 텍스트에서 정보를 추출하기 위한 명확한 지침과 추가 컨텍스트를 제공합니다.\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\n",
    "            \"당신은 전문 정보 추출 알고리즘입니다. \"\n",
    "            \"텍스트에서 관련 정보만 추출하세요. \"\n",
    "            \"추출해야 할 속성의 값을 알지 못할 경우, \"\n",
    "            \"해당 속성의 값으로 null을 반환하세요.\"\n",
    "            \"한국어로 반환하세요.\"\n",
    "        ),\n",
    "        (\"user\", \"{text}\"),   # 사용자 입력 텍스트를 프롬프트에 전달\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bf6a1-8e0c-4b6a-aa37-12fe9c42a6d9",
   "metadata": {
    "id": "832bf6a1-8e0c-4b6a-aa37-12fe9c42a6d9"
   },
   "source": [
    "**기능/도구 호출(Function/Tool Calling)** 을 지원하는 모델을 사용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e409c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\")\n",
    "# model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e0ab0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10f7e84d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10f8f2050>, root_client=<openai.OpenAI object at 0x10f052450>, root_async_client=<openai.AsyncOpenAI object at 0x10f8f1d50>, model_name='gpt-5-nano', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'response_format': <class '__main__.Person'>, 'ls_structured_output_format': {'kwargs': {'method': 'json_schema', 'strict': None}, 'schema': {'type': 'function', 'function': {'name': 'Person', 'description': '사람에 대한 정보.\\n- 모든 필드는 선택적(optional)입니다.  \\n- 각 필드는 `description`을 포함하며, LLM이 이를 활용하여 정확한 추출 결과를 생성합니다.', 'parameters': {'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': '사람의 이름'}, 'hair_color': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': '사람의 머리 색상'}, 'height_in_meters': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': '미터 단위로 측정된 키'}}, 'type': 'object'}}}}}, config={}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(...), kwargs={}, config={}, config_factories=[], custom_output_type=<class '__main__.Person'>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM에서 구조화된 출력을 생성하도록 스키마 바인딩\n",
    "structured_llm = model.with_structured_output(schema=Person)\n",
    "structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908bca50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Smith', 'hair_color': '금발', 'height_in_meters': '1.86'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Smith의 키는 186센티이고 금발입니다.\"\n",
    "\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "response = structured_llm.invoke(prompt)\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c493d-f9dc-4236-8da9-50f6919f5710",
   "metadata": {
    "id": "bd1c493d-f9dc-4236-8da9-50f6919f5710"
   },
   "source": [
    "LLM은 생성 모델이므로, 센티미터로 제공된 신장의 정보를 미터로 정확하게 추출하는 등의 놀라운 작업을 수행할 수 있습니다! 또한 스키마에 정의된 이름, 머리색, 키 외의 다른 내용은 무시하고 답변을 생성합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5ef0c-b8d1-4e12-bd0e-e2528de87fcc",
   "metadata": {
    "id": "28c5ef0c-b8d1-4e12-bd0e-e2528de87fcc"
   },
   "source": [
    "## 다중 엔터티\n",
    "\n",
    "많은 경우, 단일 엔티티가 아닌 여러 엔티티를 추출해야 합니다. 이는 Pydantic에서 모델을 서로 중첩하여 쉽게 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d348a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"\n",
    "    여러 사람들에 대한 추출된 데이터.\n",
    "    \"\"\"\n",
    "    peoples: List[Person]   # 여러 사람의 정보를 추출하기 위해 'Person' 모델의 리스트를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e18882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'peoples': [{'name': '제프', 'hair_color': '검은색', 'height_in_meters': '1.83'},\n",
       "  {'name': '안나', 'hair_color': '검은색', 'height_in_meters': None}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = model.with_structured_output(schema=Data)\n",
    "\n",
    "text = \"제 이름은 제프이고, 제 머리는 검은색이고 키는 6피트입니다. 안나는 저와 같은 색의 머리를 가지고 있습니다.\"\n",
    "\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "response = structured_llm.invoke(prompt)\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1d770-bf4d-4de4-9e4f-7384872ef0dc",
   "metadata": {
    "id": "fba1d770-bf4d-4de4-9e4f-7384872ef0dc"
   },
   "source": [
    "**여러 엔티티**를 추출할 수 있도록 스키마가 설계되면, 텍스트에 관련 정보가 없을 경우 **빈 리스트(empty list)** 를 반환하여 **아무런 엔티티도 추출하지 않을 수 있습니다.**  \n",
    "\n",
    "이는 일반적으로 **좋은 설계**입니다! 이를 통해 모델이 해당 엔티티를 반드시 감지하도록 강제하지 않을 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a70bfd37-8359-4b16-a2dc-13dbb20ece1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'peoples': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"하늘은 파랗고 나무는 푸르다.\"\n",
    "\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "dict(structured_llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82063de3-7b02-4d9f-bcde-19e1a4407ea4",
   "metadata": {},
   "source": [
    "## 구조화된 출력 (Structured Outputs)과 함수 호출 (Pydantic 기반)\n",
    "\n",
    "일반적인 챗봇은 모델이 **자연어로 직접 응답**하지만,  \n",
    "데이터 분석·API 호출·데이터베이스 저장 같은 상황에서는  \n",
    "모델이 **정해진 구조(스키마)** 에 맞게 출력을 내보내야 합니다.  \n",
    "이를 **구조화된 출력(Structured Output)** 이라고 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 핵심 포인트\n",
    "\n",
    "- **자연어 응답이 아닌 구조화된 데이터(JSON 형태)** 로 응답.  \n",
    "- **데이터베이스, API, 파이프라인** 등과의 호환성 보장.  \n",
    "- **Pydantic 스키마**로 검증된 일관된 데이터 형식 확보.\n",
    "\n",
    "---\n",
    "\n",
    "### 구조화된 출력 + 함수 호출 예제 (Pydantic 기반)\n",
    "\n",
    "1. **Pydantic 스키마 정의**  \n",
    "   모델이 따라야 할 출력 구조를 정의합니다.\n",
    "   ```python\n",
    "   class GeoQuery(BaseModel):\n",
    "       \"\"\"위도와 경도 정보를 포함한 위치 데이터\"\"\"\n",
    "       latitude: float = Field(..., description=\"위도 (−90 ~ 90)\")\n",
    "       longitude: float = Field(..., description=\"경도 (−180 ~ 180)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67c914b-e453-4f49-ac95-4c9a5cbe7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import requests\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "# 외부 API 호출 함수\n",
    "def get_temperature(latitude: float, longitude: float) -> float:\n",
    "    \"\"\"Open-Meteo에서 현재 기온(°C)을 조회\"\"\"\n",
    "    url = (\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m\"\n",
    "    )\n",
    "    resp = requests.get(url, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    return float(data[\"current\"][\"temperature_2m\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dfe20b8-b936-4491-8995-d55628444e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: 서울의 현재 날씨를 알려줘.\n",
      "추출 좌표: {'latitude': 37.5665, 'longitude': 126.978}\n",
      "현재 기온(°C): 24.5\n",
      "LLM이 생성한 최종 응답: 현재 서울의 기온은 24.5°C로 밖에 나가기에 꽤 쾌적한 날씨예요. 가볍게 반팔 차림으로도 충분하지만 햇빛이 강할 수 있으니 야외 활동 시 자외선 차단제와 모자, 얕은 겉옷 정도를 챙기는 게 좋습니다. 한낮에는 조금 더울 수 있으니 물을 자주 마시고, 땀을 많이 흘리면 실내로 들어가 휴식을 취하는 것도 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# Pydantic 스키마 정의 (LLM이 이 스키마를 참고해 JSON 생성 -> 파이썬에서 검증/파싱)\n",
    "class GeoQuery(BaseModel):\n",
    "    \"\"\"\n",
    "    사용자가 지정한 위치의 좌표.\n",
    "    - 모든 값은 십진수 좌표이며, 범위 검증을 수행합니다.\n",
    "    - 예) 서울: (37.5665, 126.9780)\n",
    "    \"\"\"\n",
    "    latitude: float = Field(..., description=\"위도 (−90 ~ 90)\")\n",
    "    longitude: float = Field(..., description=\"경도 (−180 ~ 180)\")\n",
    "\n",
    "llm_with_structure = model.with_structured_output(schema=GeoQuery)\n",
    "\n",
    "user_input = \"서울의 현재 날씨를 알려줘.\"\n",
    "\n",
    "# 좌표 추출 (LLM이 JSON 생성 -> Pydantic이 객체화)\n",
    "# coords는 GeoQuery 인스턴스 (예: GeoQuery(latitude=37.5665, longitude=126.9780))\n",
    "coords: GeoQuery = llm_with_structure.invoke(user_input)\n",
    "\n",
    "# 도구(외부 API) 호출\n",
    "temperature = get_temperature(coords.latitude, coords.longitude)\n",
    "\n",
    "# 최종 응답 생성\n",
    "final_prompt = (\n",
    "    f\"현재 서울(위도 {coords.latitude}, 경도 {coords.longitude})의 기온은 \"\n",
    "    f\"{temperature}°C입니다. 사용자가 이해하기 쉽게 자연스러운 한국어로 한 문단으로 답변하세요.\"\n",
    ")\n",
    "final_response = model.invoke(final_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"사용자 질문:\", user_input)\n",
    "print(\"추출 좌표:\", coords.model_dump())\n",
    "print(\"현재 기온(°C):\", temperature)\n",
    "print(\"LLM이 생성한 최종 응답:\", final_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc59b5b-9fcd-4556-9db7-0bbf45f00683",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "### 실습 문제: Open-Meteo API를 이용한 실제 날씨 정보 조회 \n",
    "\n",
    "**목표:**\n",
    "사용자가 \"xx 도시의 날씨를 알려줘\"라고 입력하면 모델이 위도/경도를 추론하고, `get_weather(latitude, longitude)` 함수를 호출한 뒤, 결과를 출력하도록 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c58de5-ca68-4e24-abb0-882f848d3dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
