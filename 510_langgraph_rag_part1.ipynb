{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5630b0ca",
   "metadata": {
    "id": "5630b0ca"
   },
   "source": [
    "# **Retrieval Augmented Generation (RAG) 애플리케이션 구축: Part 1**\n",
    "\n",
    "### 자신만의 문서를 활용하여 응답을 생성하는 애플리케이션 구축\n",
    "\n",
    "- **Part 1**: RAG 개념을 소개하고, 최소한의 구현 방법을 설명합니다.  \n",
    "- **Part 2** 기존 구현을 확장하여 대화형 상호작용과 다단계 검색 프로세스를 처리할 수 있도록 개선합니다.\n",
    "---\n",
    "\n",
    "## 전형적인 **RAG 애플리케이션**\n",
    "\n",
    "두 가지 주요 구성 요소로 이루어져 있습니다:  \n",
    "\n",
    "1. **인덱싱(Indexing)**: 데이터 소스를 수집하고 인덱싱하는 파이프라인입니다. *일반적으로 오프라인에서 수행됩니다.*  \n",
    "2. **검색 및 생성(Retrieval and Generation)**: 실행 시간에 사용자 쿼리를 받아 인덱스에서 관련 데이터를 검색한 후, 모델에 전달하여 답변을 생성합니다.  \n",
    "\n",
    "---\n",
    "\n",
    "### **인덱싱 단계**  \n",
    "일반적인 데이터 인덱싱 과정은 다음과 같습니다:  \n",
    "\n",
    "1. **로드(Load)**  \n",
    "   - 먼저 데이터를 불러와야 합니다. 이는 문서 로더(Document Loaders)를 사용하여 수행됩니다.  \n",
    "\n",
    "2. **분할(Split)**  \n",
    "   - 텍스트 분할기(Text Splitters)를 사용해 큰 `문서(Document)`를 작은 청크(chunk)로 나눕니다.  \n",
    "   - 이렇게 하면 검색이 더 효율적이며, 모델의 제한된 컨텍스트 윈도우에 맞출 수 있습니다.  \n",
    "\n",
    "3. **저장(Store)**  \n",
    "   - 분할된 데이터를 저장하고 인덱싱할 장소가 필요합니다.  \n",
    "   - 일반적으로 벡터 스토어(VectorStore)와 임베딩 모델(Embeddings)을 사용합니다.  \n",
    "---\n",
    "\n",
    "### **검색 및 생성 단계**  \n",
    "\n",
    "일반적인 검색 및 생성 과정은 다음과 같습니다:  \n",
    "\n",
    "4. **검색(Retrieve)**  \n",
    "   - 사용자 입력을 받아 검색기(Retriever)를 사용하여 저장된 데이터에서 관련 청크를 검색합니다.  \n",
    "\n",
    "5. **생성(Generate)**  \n",
    "   - 챗 모델(ChatModel) 또는 LLM이 검색된 데이터를 포함한 프롬프트를 사용해 답변을 생성합니다.  \n",
    "\n",
    "\n",
    "인덱싱이 완료된 후에는 LangGraph를 오케스트레이션 프레임워크로 사용하여 **검색 및 생성 단계**를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f3a87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba74a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\")\n",
    "# model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "# 사용할 임베딩 모델의 이름을 지정\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92cbc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InMemoryVectorStore - 메모리 내에서 벡터 데이터를 저장 및 빠른 검색\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2d316-922c-4318-b72d-486fd6813b94",
   "metadata": {
    "id": "93b2d316-922c-4318-b72d-486fd6813b94"
   },
   "source": [
    "이  노트북에서는 **웹사이트 콘텐츠에 대한 질문에 답변하는 애플리케이션**을 구축합니다.  \n",
    "**텍스트를 로드, 분할, 인덱싱**한 후, **사용자 질문을 기반으로 관련 데이터를 검색**하고 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10644e09-b667-4a28-b066-5447339125a0",
   "metadata": {},
   "source": [
    "## **단계별 상세 설명**\n",
    "\n",
    "## **1. 인덱싱 (Indexing)**\n",
    "\n",
    "### **문서 불러오기 (Loading Documents)**\n",
    "\n",
    "먼저 **Document Loaders** 중 **[WebBaseLoader](https://python.langchain.com/docs/integrations/document_loaders/web_base/)** 를 사용하여 블로그 게시물의 내용을 불러옵니다. \n",
    "\n",
    "* `WebBaseLoader`클라스는 내부적으로 `urllib`을 사용해 **웹 URL에서 HTML을 로드**합니다.\n",
    "* 이후, `BeautifulSoup`을 사용해 **텍스트로 파싱**하고 **Document** 객체 목록으로 반환합니다.\n",
    "\n",
    "#### **HTML → 텍스트 변환 커스터마이징**\n",
    "\n",
    "* 우리는 `<h1>`, `<h2>`, `<h3>`, `<p>`, `<pre>`, `<li>` 등 주요 콘텐츠를 포함하는 태그만 추출하도록 설정합니다.\n",
    "* 또한 일부 웹사이트에서는 User-Agent를 설정하지 않으면 콘텐츠를 차단할 수 있으므로, `requests_kwargs`를 사용해 User-Agent를 지정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06fc9cc-1bd5-42d0-a0a8-cd6d93b7410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 8582\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 주요 콘텐츠 태그만 필터링 (제목, 본문, 코드 등)\n",
    "bs4_strainer = bs4.SoupStrainer(name=(\"h1\", \"h2\", \"h3\", \"p\", \"pre\", \"li\"))\n",
    "\n",
    "# WebBaseLoader 사용: requests_kwargs로 User-Agent 설정\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://botpress.com/ko/blog/llm-agents\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    "    requests_kwargs={\n",
    "        \"headers\": {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 결과 확인\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8643579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8582\n",
      "LLM 에이전트 완전 가이드 (2025)LLM 에이전트는 언어 이해, 기억력, 도구 사용 및 계획 능력을 결합하여 단순한 채팅을 넘어 복잡하고 자율적인 작업을 수행할 수 있습니다.LLM 에이전트를 개선하려면 정확성과 안정성을 높이기 위해 RAG, 미세 조정, n-샷 프롬프트, 고급 프롬프트 엔지니어링과 같은 기술이 필요합니다.LLM 에이전트를 구축하려면 명확한 목표, 적합한 플랫폼, 모델 구성, 통합, 테스트 및 지속적인 모니터링이 필요합니다.강력한 기능에도 불구하고 LLM 에이전트에는 환각, 개인정보 보호 위험, 컨텍스트 제약 등의 한계가 있으므로 신중한 설계와 감독이 필수적입니다.올해 가장 뜨거운 화두인 AI 에이전트에 대해 잘 알고 계실 겁니다: 바로 AI 에이전트입니다. 이러한 AI 에이전트의 대부분은 LLM 에이전트입니다 . 왜 그럴까요?\"지난 몇 년 동안 자율 에이전트에는 많은 변화가 있었습니다.\"라고 Botpress CEO Sylvain Perron 설명합니다. \"기본 \n"
     ]
    }
   ],
   "source": [
    "# 문서 길이\n",
    "print(len(docs[0].page_content))\n",
    "# 첫번째 500 자 출력\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f11795-e19f-4697-bc6e-6d477355a1cd",
   "metadata": {
    "id": "e6f11795-e19f-4697-bc6e-6d477355a1cd"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **문서 분할 (Splitting documents)**  \n",
    "\n",
    "문서 길이가 언어 모델의 **컨텍스트 윈도우(context window)** 에 넣기에 너무 길 경우, 너무 긴 입력은 **정보를 효과적으로 찾아내기 어려울 수 있습니다.**  \n",
    "\n",
    "이 문제를 해결하기 위해, **`Document`를 작은 청크(chunk)로 분할**하여 **임베딩(embedding)** 및 **벡터 저장(vector storage)** 에 사용합니다.  \n",
    "이렇게 하면 블로그 게시물의 **가장 관련성 높은 부분만 검색**할 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "**RecursiveCharacterTextSplitter**는 문서를 **공통 구분자(예: 줄바꿈)** 를  사용해 재귀적으로 분할합니다.  일반적인 텍스트 사용 사례에 가장 적합한 텍스트 분할기입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6606d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "블로그 글을 11개의 하위 문서로 분할했습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,            # 각 청크의 최대 문자 수 (1,000자)\n",
    "    chunk_overlap=200,          # 청크 간 겹치는 문자 수 (200자)\n",
    "    add_start_index=True,       # 원본 문서에서 각 청크의 시작 인덱스를 추적\n",
    ")\n",
    "\n",
    "# 불러온 문서를 설정한 기준에 따라 청크로 분할\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 분할된 청크(서브 문서)의 개수 출력\n",
    "print(f\"블로그 글을 {len(all_splits)}개의 하위 문서로 분할했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "024f0446-4d6b-488e-afd2-073a992f3e94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 0}, page_content='LLM 에이전트 완전 가이드 (2025)LLM 에이전트는 언어 이해, 기억력, 도구 사용 및 계획 능력을 결합하여 단순한 채팅을 넘어 복잡하고 자율적인 작업을 수행할 수 있습니다.LLM 에이전트를 개선하려면 정확성과 안정성을 높이기 위해 RAG, 미세 조정, n-샷 프롬프트, 고급 프롬프트 엔지니어링과 같은 기술이 필요합니다.LLM 에이전트를 구축하려면 명확한 목표, 적합한 플랫폼, 모델 구성, 통합, 테스트 및 지속적인 모니터링이 필요합니다.강력한 기능에도 불구하고 LLM 에이전트에는 환각, 개인정보 보호 위험, 컨텍스트 제약 등의 한계가 있으므로 신중한 설계와 감독이 필수적입니다.올해 가장 뜨거운 화두인 AI 에이전트에 대해 잘 알고 계실 겁니다: 바로 AI 에이전트입니다. 이러한 AI 에이전트의 대부분은 LLM 에이전트입니다 . 왜 그럴까요?\"지난 몇 년 동안 자율 에이전트에는 많은 변화가 있었습니다.\"라고 Botpress CEO Sylvain Perron 설명합니다. \"기본 모델이 개선되었습니다. LLMs 추론과 추상화의 새로운 계층을 열었습니다.\"LLMs 강력한 기능을 통해 모든 종류의 언어 기반 또는 추론 작업을 완료하도록 AI 에이전트를 구축할 수 있습니다.그리고 언어와 분석 능력 덕분에 향후 몇 년 내에 80% 이상의 기업이 AI 에이전트를 사용할 계획을 세우는 등 화이트칼라 직장을 서서히 대체하고 있습니다.AI 에이전트의 넓은 범주에는 비언어적 애플리케이션(콘텐츠 추천 시스템, 이미지 인식, 로봇 제어 등)이 포함되지만, LLM 에이전트는 일반적으로 대화형 AI 소프트웨어입니다.\\xa0LLM 에이전트란 무엇인가요?LLM 에이전트는 대규모 언어 모델을 사용하여 언어를 해석하고, 대화를 나누고, 작업을 수행하는 AI 기반 도구입니다.이러한 에이전트는 방대한 양의 텍스트 데이터로 학습된 복잡한 알고리즘을 기반으로 구축되어 인간과 유사한 방식으로 언어를 이해하고 생성할 수 있습니다.\\xa0LLM 에이전트를 AI 에이전트, AI 챗봇, 가상 비서, 콘텐츠 생성'),\n",
       " Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 803}, page_content=\"무엇인가요?LLM 에이전트는 대규모 언어 모델을 사용하여 언어를 해석하고, 대화를 나누고, 작업을 수행하는 AI 기반 도구입니다.이러한 에이전트는 방대한 양의 텍스트 데이터로 학습된 복잡한 알고리즘을 기반으로 구축되어 인간과 유사한 방식으로 언어를 이해하고 생성할 수 있습니다.\\xa0LLM 에이전트를 AI 에이전트, AI 챗봇, 가상 비서, 콘텐츠 생성 소프트웨어 및 기타 응용 도구에 통합할 수 있습니다.LLM 에이전트는 어떻게 작동하나요?LLM 에이전트는 검색, 추론, 메모리 및 도구 사용과 LLM 기능을 결합하여 자율적으로 작업을 완료합니다. 이러한 각 구성 요소의 기능을 자세히 살펴보겠습니다.\\u200d이러한 기능을 함께 사용하면 LLM 에이전트가 완전한 자율성을 가지고 복잡한 다단계 워크플로우를 수행할 수 있습니다.\\xa0예를 들어B2B 영업 에이전트는 잠재 고객의 CRM 데이터를 검색하고, 거래 진행 상황을 분석하고, 잠재 고객과의 과거 상호 작용을 기억하여 후속 조치를 맞춤화하고, 이메일 및 캘린더 API를 사용하여 전송 및 일정을 잡습니다.IT 상담원은 시스템 로그를 검색하여 오류를 진단하고, 최상의 전략을 위해 문제 해결 단계를 분석하며, 이전 사용자 문제에서 효과가 있었던 것을 기억하고, 스크립트를 실행하여 서비스를 다시 시작하거나 티켓을 작성합니다.LLM 에이전트를 정의하는 4가지 기능은 무엇인가요?LLM 상담원에는 네 가지 주요 기능이 있습니다:1. 언어 모델\\xa0언어 모델은 종종 LLM 에이전트의 '두뇌'로 간주됩니다. 그 품질과 규모는 LLM 에이전트의 성능에 직접적인 영향을 미칩니다.방대한 텍스트 데이터 세트를 학습한 정교한 알고리즘으로, 문맥을 이해하고 패턴을 인식하며 일관되고 맥락에 맞는 응답을 생성할 수 있습니다.언어 패턴 식별 및 학습방대한 학습 데이터를 통해 어느 정도의 상황 인식 능력 향상다양한 도메인에 적응하고 다양한 주제를 처리하세요.언어 모델은 상담원의 언어 능력의 기초가 되는 응답의 깊이, 정확성 및 관련성을 결정합니다.\\xa02.\"),\n",
       " Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 1598}, page_content=\"데이터 세트를 학습한 정교한 알고리즘으로, 문맥을 이해하고 패턴을 인식하며 일관되고 맥락에 맞는 응답을 생성할 수 있습니다.언어 패턴 식별 및 학습방대한 학습 데이터를 통해 어느 정도의 상황 인식 능력 향상다양한 도메인에 적응하고 다양한 주제를 처리하세요.언어 모델은 상담원의 언어 능력의 기초가 되는 응답의 깊이, 정확성 및 관련성을 결정합니다.\\xa02. 메모리메모리는 사실, 사용자 선호도 또는 세션 전반의 주제와 같은 과거 상호 작용에서 얻은 정보를 유지하는 기능을 말합니다.\\xa0이를 통해 상담원의 문맥 이해도가 향상되고 대화가 더욱 연속적이고 관련성이 높아집니다.\\xa0일부 설정에서는 메모리를 통해 상담원이 시간이 지나도 정보를 유지할 수 있습니다. 이는 상담원이 반복되는 사용자 행동이나 선호도를 통해 '학습'하는 장기적인 상호작용을 지원하지만, 개인정보 보호 및 관련성을 위해 규제되는 경우가 많습니다.3. 도구 사용이 도구를 사용하면 LLM 상담원이 대화에서 행동으로 옮길 수 있습니다.\\xa0LLM 에이전트는 외부 애플리케이션, 데이터베이스 또는 API와 통합하여 특정 기능을 수행할 수 있습니다.\\xa0즉, 실시간 정보를 가져오고, 외부 작업을 실행하거나, 특수 데이터베이스에 액세스하여 실시간 정보를 제공할 수 있는 기능을 제공합니다. 여기에는 다음이 포함됩니다:API 호출하기날씨 업데이트나 주가 같은 실시간 데이터 가져오기회의 또는 약속 예약하기제품 카탈로그나 인사 정책 문서와 같은 데이터베이스 쿼리하기툴을 사용하면 LLM 상담원이 수동적인 지식 기반 시스템에서 다른 시스템과 상호 작용할 수 있는 능동적인 참여자로 전환할 수 있습니다.4. 계획\\xa0계획은 LLM 상담원이 복잡한 작업을 관리 가능한 일련의 단계로 세분화하는 기능입니다.\\xa0LLM 상담원은 피드백을 받거나 받지 않고 계획을 세울 수 있습니다. 어떤 차이가 있을까요?피드백 없이 계획을 세우면 LLM 상담원이 초기 이해를 바탕으로 계획을 작성합니다. 더 빠르고 간단하지만 적응력이 부족합니다.피드백이 포함된 계획은 LLM\"),\n",
       " Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 2397}, page_content='수 있습니다.4. 계획\\xa0계획은 LLM 상담원이 복잡한 작업을 관리 가능한 일련의 단계로 세분화하는 기능입니다.\\xa0LLM 상담원은 피드백을 받거나 받지 않고 계획을 세울 수 있습니다. 어떤 차이가 있을까요?피드백 없이 계획을 세우면 LLM 상담원이 초기 이해를 바탕으로 계획을 작성합니다. 더 빠르고 간단하지만 적응력이 부족합니다.피드백이 포함된 계획은 LLM 상담원이 환경의 의견을 반영하여 계획을 지속적으로 개선할 수 있음을 의미합니다. 더 복잡하지만 훨씬 더 유연하고 시간이 지남에 따라 성능이 향상됩니다.\\xa0LLM 상담원은 계획을 통해 솔루션을 향해 점진적으로 이동하는 논리적 흐름을 만들 수 있으므로 복잡한 요청을 보다 효과적으로 처리할 수 있습니다.LLM 에이전트의 4가지 유형은 무엇인가요?1. 대화형 상담원(예: 고객 지원 및 리드 생성)이러한 유형의 상담원은 사용자와 자연스럽게 대화를 나누며 정보를 제공하고 질문에 답하며 다양한 작업을 지원합니다.\\xa0이러한 에이전트는 LLMs 을 사용하여 사람과 유사한 응답을 이해하고 생성합니다.\\xa0예시: 예: 고객 지원 상담원 및 의료 챗봇2. 작업 지향 에이전트(예: AI 어시스턴트 및 AI 워크플로) 2.특정 작업을 수행하거나 미리 정의된 목표를 달성하는 데 중점을 둔 이러한 에이전트는 사용자와 상호 작용하여 사용자의 요구 사항을 파악한 다음 이러한 요구 사항을 충족하기 위한 작업을 실행합니다.예시  예:AI 어시스턴트 및 HR 봇3. 크리에이티브 에이전트(예: 콘텐츠 제작 도구)예술 작품, 음악, 글쓰기 등 독창적이고 창의적인 콘텐츠를 제작할 수 있는 이 에이전트는 LLMs 을 통해 사람들의 선호도와 예술적 스타일을 파악하여 시청자의 공감을 이끌어내는 콘텐츠를 제작할 수 있습니다.\\xa0예시 예: 콘텐츠 생성 도구 및 이미지 생성 도구(예: Dall-E)4. 협업 에이전트(예: 엔터프라이즈 AI 에이전트)이러한 에이전트는 인간과 함께 공동의 목표나 작업을 수행하며 팀원 간 또는 인간과 기계 간의 커뮤니케이션, 조정, 협력을'),\n",
       " Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 3200}, page_content='을 통해 사람들의 선호도와 예술적 스타일을 파악하여 시청자의 공감을 이끌어내는 콘텐츠를 제작할 수 있습니다.\\xa0예시 예: 콘텐츠 생성 도구 및 이미지 생성 도구(예: Dall-E)4. 협업 에이전트(예: 엔터프라이즈 AI 에이전트)이러한 에이전트는 인간과 함께 공동의 목표나 작업을 수행하며 팀원 간 또는 인간과 기계 간의 커뮤니케이션, 조정, 협력을 촉진합니다.\\xa0LLMs 는 의사 결정을 지원하거나 보고서를 생성하거나 인사이트를 제공함으로써 공동 작업 에이전트를 지원할 수 있습니다.예시: 대부분의 엔터프라이즈 AI 에이전트 및 프로젝트 관리 챗봇기업에서는 LLM 에이전트를 어떻게 사용하나요?기업은 질문 답변, 안내 제공, 워크플로 자동화, 텍스트 분석 등 자연어 처리 및 응답과 관련된 영역에서 LLM 에이전트의 이점을 누릴 수 있습니다.기업에서는 마케팅, 데이터 분석, 규정 준수, 법률 지원, 의료 지원, 재무 업무 및 교육을 위해 LLM 에이전트를 자주 사용합니다.\\xa0다음은 LLM 상담원의 가장 인기 있는 사용 사례 3가지입니다:고객 지원자동화 전문가인 파스칼 보네가 167개 기업을 대상으로 실시한 연구에 따르면 고객 서비스는 LLM 에이전트 도입의 가장 인기 있는 사용 사례입니다.LLM 상담원은 고객 지원에서 자주 묻는 질문을 처리하고 문제를 해결하며 연중무휴 24시간 지원을 제공하는 데 널리 사용됩니다.\\xa0이러한 상담원은 실시간으로 고객과 소통하여 즉각적인 도움을 제공하거나 복잡한 문의를 인간 상담원에게 에스컬레이션할 수 있습니다.참조하세요: 고객 서비스 챗봇이란 무엇인가요?영업 및 리드 생성영업 분야에서 LLM 에이전트는 AI 리드 생성에 사용되며, 잠재 고객을 대화에 참여시키고, 요구 사항을 평가하고, 가치 있는 정보를 수집하여 리드의 자격을 부여할 수도 있습니다.\\xa0또한 후속 상호 작용을 자동화하여 고객의 관심사에 따라 개인화된 추천 또는 제품 정보를 전송할 수 있습니다.\\xa0참조하세요: 영업에 AI를 사용하는 방법내부 지원 HR 및 IT내부 지원의 경우,'),\n",
       " Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 3998}, page_content='LLM 에이전트는 AI 리드 생성에 사용되며, 잠재 고객을 대화에 참여시키고, 요구 사항을 평가하고, 가치 있는 정보를 수집하여 리드의 자격을 부여할 수도 있습니다.\\xa0또한 후속 상호 작용을 자동화하여 고객의 관심사에 따라 개인화된 추천 또는 제품 정보를 전송할 수 있습니다.\\xa0참조하세요: 영업에 AI를 사용하는 방법내부 지원 HR 및 IT내부 지원의 경우, LLM 상담원은 직원들의 일반적인 문의를 처리하여 HR 및 IT 프로세스를 간소화합니다. 실제로 보넷의 연구에 따르면 내부 업무에서 LLM 에이전트가 가장 비용 효율적이며, 기존 내부 업무 수행에 소요되던 시간의 30~90%를 절약할 수 있는 것으로 나타났습니다.HR에서는 복리후생, 휴가 정책, 급여와 같은 주제에 대한 질문에 답변하고, IT에서는 기본적인 기술 문제에 대한 문제 해결을 제공하거나 계정 설정과 같은 일상적인 작업을 자동화합니다.\\xa0이를 통해 HR 및 IT 팀은 반복적인 바쁜 업무 대신 더 복잡한 책임에 집중할 수 있습니다.참조하세요: HR을 위한 최고의 AI 상담원개선 방법 LLM 에이전트 응답AI 프로젝트에 맞춰 LLM 맞춤 설정 하는 경우, 공개 모델이 사용자에게 제공하는 표준 응답을 조정해야 합니다. (챗봇이 경쟁 제품을 추천하게 할 수는 없잖아요?) 또한, 무작위 언어 생성보다는 훈련된 직원처럼 작동하도록 맞춤형 비즈니스 로직을 사용하고 싶을 수도 있습니다. 품질을 향상시키는 4가지 일반적인 개념이 있습니다. LLM 응답: RAG미세 조정N샷 프롬프트신속한 엔지니어링1. 검색 증강 생성RAG는 ChatGPT 에 텍스트를 붙여넣고 ChatGPT 에 질문을 하는 간단한 작업의 멋진 이름입니다. 일반적인 예로는 전자상거래 사이트에 특정 제품의 재고가 있는지 묻는 경우 챗봇이 광범위한 인터넷 대신 제품 카탈로그에서 정보를 조회하는 것을 들 수 있습니다. 개발 속도와 실시간 정보 획득 측면에서 RAG는 반드시 필요한 기능입니다. 일반적으로 어떤 모델을 선택할지는 영향을 미치지 않지만, 정보를'),\n",
       " Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 4802}, page_content='에 질문을 하는 간단한 작업의 멋진 이름입니다. 일반적인 예로는 전자상거래 사이트에 특정 제품의 재고가 있는지 묻는 경우 챗봇이 광범위한 인터넷 대신 제품 카탈로그에서 정보를 조회하는 것을 들 수 있습니다. 개발 속도와 실시간 정보 획득 측면에서 RAG는 반드시 필요한 기능입니다. 일반적으로 어떤 모델을 선택할지는 영향을 미치지 않지만, 정보를 쿼리하고 답변을 제공하는 LLM API 엔드포인트를 만들고 이 엔드포인트를 마치 자체적인 것처럼 사용하는 것을 막을 수는 없습니다 LLM. 지식 기반 챗봇에 RAG를 사용하면 모델을 미세 조정하고 최신 상태로 유지할 필요가 없으므로 유지 관리가 더 쉬우며 비용도 절감할 수 있습니다.2. 미세 조정 미세 조정에는 특정 작업을 잘 수행하는 방법을 학습할 수 있도록 모델에 예시를 제공하는 것이 포함됩니다. 제품에 대해 잘 말하도록 하려면 회사의 최고의 영업 통화 사례를 많이 제공할 수 있습니다.모델이 오픈 소스인 경우, 팀에 모델을 미세 조정할 수 있는 엔지니어링 역량이 충분한지 자문해 보세요.모델이 비공개 소스이고 서비스로 제공되는 경우( GPT-4 또는 Claude) 일반적으로 엔지니어가 API를 사용하여 사용자 지정 모델을 미세 조정하도록 할 수 있습니다. 이 방법을 사용하면 일반적으로 가격이 크게 상승하지만 유지 관리가 거의 또는 전혀 필요하지 않습니다. 하지만 많은 사용 사례에서 미세 조정이 모델 최적화를 위한 첫 번째 단계는 아닙니다. 미세 조정을 위한 좋은 사례는 정적 지식에 대한 지식 봇을 구축하는 것입니다. 질문과 답변의 예를 제공하면 나중에 답을 찾지 않고도 답을 찾을 수 있어야 합니다. 하지만 실시간 정보에 대한 실용적인 솔루션은 아닙니다. 3. N-샷 러닝 응답 품질을 개선하는 가장 빠른 방법은 LLM API 호출 한 번으로 예제를 제공하는 것입니다. 제로 샷(답변에서 찾고 있는 내용에 대한 예시를 하나도 제시하지 않는 것)은 대부분의 사람들이 ChatGPT 을 사용하는 방식입니다. 일반적으로 예제'),\n",
       " Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 5600}, page_content='않고도 답을 찾을 수 있어야 합니다. 하지만 실시간 정보에 대한 실용적인 솔루션은 아닙니다. 3. N-샷 러닝 응답 품질을 개선하는 가장 빠른 방법은 LLM API 호출 한 번으로 예제를 제공하는 것입니다. 제로 샷(답변에서 찾고 있는 내용에 대한 예시를 하나도 제시하지 않는 것)은 대부분의 사람들이 ChatGPT 을 사용하는 방식입니다. 일반적으로 예제 하나(또는 원샷)를 추가하는 것만으로도 응답 품질이 크게 향상되는 것을 볼 수 있습니다. 두 개 이상의 예가 N샷으로 간주됩니다. N샷은 미세 조정과 달리 모델을 변경하지 않습니다. 단순히 질문을 할 때마다 답변을 요청하기 직전에 예시를 제시하는 것입니다. LLM 모델은 최대 컨텍스트 크기가 있으며 메시지 크기에 따라 요금이 책정되므로 이 전략을 남용해서는 안 됩니다. 미세 조정을 통해 N샷 예시가 필요하지 않을 수 있지만 올바르게 설정하는 데 시간이 더 걸립니다. 4. 신속한 엔지니어링 기술모델이 답을 내놓기 전에 큰 소리로 생각하도록 하는 연쇄적 사고와 같은 다른 즉각적인 엔지니어링 기법도 있습니다. 또한, 여러 프롬프트를 순서대로 실행하여 모델이 복잡한 작업을 더 작은 단계로 나누도록 하는 프롬프트 체이닝 도 있습니다. 이러한 전략을 사용하면 응답의 품질과 안정성을 크게 높일 수 있습니다(특히 추론 중심 작업의 경우). 하지만 응답 시간이 길어지고 토큰 사용량이 늘어나며 성능이 저하되는 경우가 많습니다.이렇게 하면 응답 품질이 향상되지만 응답 시간, 비용 및 속도가 희생됩니다. 빌드하는 방법 LLM 6단계로 에이전트를 만나보세요1. 목표 정의AI 에이전트나 챗봇을 구축하는 첫 번째 단계는 정확히 무엇을 달성하고자 하는지를 파악하는 것입니다.고객 문의 지원, 콘텐츠 생성, 특정 작업 처리 등 LLM 상담원이 달성하기를 원하는 목표를 명확히 하세요.\\xa0명확한 목표를 파악하면 상담원의 설정 및 구성이 구체화됩니다.2. AI 플랫폼 선택최고의 AI 플랫폼은 전적으로 사용자의 목표와 필요에 따라'),\n",
       " Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 6392}, page_content='정의AI 에이전트나 챗봇을 구축하는 첫 번째 단계는 정확히 무엇을 달성하고자 하는지를 파악하는 것입니다.고객 문의 지원, 콘텐츠 생성, 특정 작업 처리 등 LLM 상담원이 달성하기를 원하는 목표를 명확히 하세요.\\xa0명확한 목표를 파악하면 상담원의 설정 및 구성이 구체화됩니다.2. AI 플랫폼 선택최고의 AI 플랫폼은 전적으로 사용자의 목표와 필요에 따라 달라집니다.\\xa0사용자 지정 옵션, 통합 기능, 사용 편의성, 지원 등의 요소를 고려하여 요구사항에 맞는 플랫폼을 선택하세요.\\xa0플랫폼은 그래야 합니다:원하는 사용 사례 지원선호하는 LLMs통합 기능 제공3. 구성 LLM플랫폼의 옵션에 따라 사전 구축된 LLM 모델을 선택하거나 필요한 경우 특수 작업에 맞게 모델을 미세 조정합니다.\\xa0많은 플랫폼에서 사전 학습되어 바로 사용할 수 있는 기본 제공 언어 모델을 제공합니다.LLM 사용법을 사용자 지정하는 데 관심이 있다면, 성장 엔지니어( Patrick Hamelin)의 AI 프로젝트를 위한 사용자 지정 LLM 옵션 선택에 관한 글을 읽어보세요.4. 도구 통합\\xa0대부분의 플랫폼은 외부 도구에 대한 연동 옵션을 제공합니다. 상담원이 액세스하는 데 필요한 모든 API, 데이터베이스 또는 리소스(예: CRM 데이터 또는 실시간 정보)를 연결하세요.5. 테스트 및 개선플랫폼의 기본 제공 테스트 도구를 사용하여 상담원을 철저하게 테스트하세요. 테스트 결과에 따라 매개변수, 프롬프트 문구 및 워크플로를 조정하여 상담원이 실제 시나리오에서 잘 작동하도록 하세요.6. 배포 및 모니터링\\xa0플랫폼의 모니터링 툴을 사용하여 배포 후 상담원의 상호작용과 성과를 추적하세요.\\xa0플랫폼에서 제공하는 피드백 메커니즘을 활용하여 필요에 따라 인사이트를 수집하고 설정을 개선하세요.사용자 지정 LLM 에이전트 배포LLM 에이전트는 고객 서비스, 내부 운영, 전자상거래 등 기업에서 대량으로 도입되고 있습니다. 도입이 느린 기업은 AI의 물결을 놓친 대가를 치르게 될 것입니다.Botpress 는 기업을 위해 구축된'),\n",
       " Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 7196}, page_content='성과를 추적하세요.\\xa0플랫폼에서 제공하는 피드백 메커니즘을 활용하여 필요에 따라 인사이트를 수집하고 설정을 개선하세요.사용자 지정 LLM 에이전트 배포LLM 에이전트는 고객 서비스, 내부 운영, 전자상거래 등 기업에서 대량으로 도입되고 있습니다. 도입이 느린 기업은 AI의 물결을 놓친 대가를 치르게 될 것입니다.Botpress 는 기업을 위해 구축된 무한히 확장 가능한 AI 에이전트 플랫폼입니다. 개발자는 stack 에서 필요한 모든 기능을 갖춘 LLM 에이전트를 구축할 수 있습니다.강화된 보안 제품군은 고객 데이터를 항상 보호하고 개발팀에서 완벽하게 제어할 수 있도록 보장합니다.지금 바로 구축을 시작하세요. 무료입니다.또는 팀에 문의하여 자세히 알아보세요.자주 묻는 질문1. LLM 상담원과 챗봇의 차이점은 무엇인가요?LLM 에이전트와 챗봇의 차이점은 챗봇은 사전 정의된 규칙이나 대화 흐름을 따르는 반면, LLM 에이전트는 대규모 언어 모델을 사용하여 의도를 이해하고, 데이터를 검색하고, 도구나 API를 사용하여 작업을 수행하고, 응답을 동적으로 조정한다는 점입니다. LLM 에이전트는 단순히 응답하는 것이 아니라 자율적으로 추론하고 행동하도록 구축되었습니다.2. LLM 에이전트가 인터넷 연결 없이도 작동할 수 있나요?LLM 에이전트는 언어 모델과 필요한 모든 도구 또는 데이터가 온프레미스에서 로컬로 호스팅되는 경우에만 인터넷 연결 없이 작동합니다. 그러나 대부분의 프로덕션 LLM 에이전트는 최신 검색이나 CRM 액세스 등의 작업을 위해 클라우드 기반 API 또는 외부 서비스에 의존합니다.3. LLM 에이전트에는 항상 언어 모델 백엔드가 필요한가요?예. 전체 아키텍처가 자연어 입력을 처리하고 출력을 생성하는 모델의 기능에 따라 달라지므로 LLM 에이전트에는 항상 언어 모델 백엔드가 필요합니다. LLM 없으면 에이전트가 사용자 프롬프트를 이해하거나 수행할 작업을 결정할 수 없습니다.4. 오늘날 LLM 에이전트 사용의 주요 제한 사항이나 위험은 무엇인가요?LLM'),\n",
       " Document(metadata={'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 7997}, page_content='항상 언어 모델 백엔드가 필요한가요?예. 전체 아키텍처가 자연어 입력을 처리하고 출력을 생성하는 모델의 기능에 따라 달라지므로 LLM 에이전트에는 항상 언어 모델 백엔드가 필요합니다. LLM 없으면 에이전트가 사용자 프롬프트를 이해하거나 수행할 작업을 결정할 수 없습니다.4. 오늘날 LLM 에이전트 사용의 주요 제한 사항이나 위험은 무엇인가요?LLM 에이전트 사용의 주요 제한 사항으로는 입/출력이 제대로 보호되지 않을 경우 환각(부정확한 응답 생성)과 잠재적인 데이터 유출이 있습니다. 또한 실제 사용 시 안정적이고 규정을 준수하는 동작을 보장하기 위해 신중한 설계와 모니터링이 필요합니다.5. 어떤 산업에서 가장 빠르게 LLM 에이전트를 도입하고 있나요?LLM 에이전트를 가장 빠르게 도입하는 산업 분야는 고객 지원, IT 서비스 관리, 의료 관리, 금융 서비스, B2B 영업 등 대량의 반복적인 언어 작업을 자동화하여 효율성과 규모를 높일 수 있는 분야입니다.AI 에이전트를 위한 인프라 계층을 구축하는 데 2,500만 달러 투자가장 흔한 챗봇 실수 11가지(AI 전문가가 알려주는)7가지 최고의 이메일 마케팅 자동화 도구(및 사용 방법)')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5193e01-6cf1-45b9-9ba5-38caf75162a6",
   "metadata": {
    "id": "f5193e01-6cf1-45b9-9ba5-38caf75162a6"
   },
   "source": [
    "### **문서 저장 (Storing documents)**\n",
    "\n",
    "이제 분할된 **텍스트 청크**를 인덱싱해야 합니다. 이를 통해 검색할 수 있습니다.  \n",
    "\n",
    "1. 각 **문서 청크**의 내용을 **임베딩(embedding)** 합니다.\n",
    "2. 이 **임베딩을 벡터 스토어(Vector Store)** 에 삽입합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8da4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a61c3f51-c233-48a6-bd8b-62704a59005d', 'b042a353-0c5d-40fe-95eb-3bf4af3c8579', '0737cd2e-dfc8-4c0a-ab69-1f3e24125c98']\n"
     ]
    }
   ],
   "source": [
    "# 분할된 문서 청크(all_splits)는 임베딩되어 벡터 스토어에 저장됩니다.\n",
    "# 반환값은 저장된 각 문서 청크의 고유 ID 목록입니다.\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# 첫 세 개의 문서 ID를 출력합니다.\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57666234-a5b3-4abc-b079-755241bb2b98",
   "metadata": {
    "id": "57666234-a5b3-4abc-b079-755241bb2b98"
   },
   "source": [
    "이로써 **인덱싱(Indexing)** 단계가 완료되었습니다!\n",
    "\n",
    "- 이제 우리는 **질의 가능한 벡터 스토어**를 보유하고 있습니다.  \n",
    "- 게시물의 청크가 저장되어 있으며, 사용자 질문을 받으면 **관련 청크를 반환**할 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "## **2. 검색 및 생성 (Retrieval and Generation)**\n",
    "\n",
    "이제 실제 **애플리케이션 로직(application logic)** 을 작성하여 다음과 같은 작업을 수행할 것입니다:  \n",
    "\n",
    "1. **사용자 질문을 입력받기**  \n",
    "2. **질문과 관련된 문서 청크 검색**  \n",
    "3. **검색된 문서와 질문을 모델에 전달**  \n",
    "4. **챗 모델(Chat Model)이 답변을 생성**  \n",
    "---\n",
    "\n",
    "### **프로세스 요약**  \n",
    "1. **사용자 질문 입력 → 문서 검색 → 답변 생성**  \n",
    "2. 관련 문서를 검색하고 질문과 함께 모델에 전달  \n",
    "3. 모델이 **최종 답변**을 생성  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08bf1ab8-586c-41f4-9f7e-9e2aed4f2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 질문에 답하는 AI 비서입니다.\"),\n",
    "    (\"human\", (\n",
    "        \"아래 제공된 문맥을 활용하여 질문에 답하세요. \"\n",
    "        \"모르면 모른다고 말하세요. \"\n",
    "        \"세 문장 이내로 간결하게 답변하세요.\\n\"\n",
    "        \"질문: {question}\\n\"\n",
    "        \"문맥: {context}\\n\"\n",
    "        \"답변:\"\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d1fb831-eaaa-4384-bdbf-f4c99c00a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== format() 결과 ===\n",
      "System: 당신은 질문에 답하는 AI 비서입니다.\n",
      "Human: 아래 제공된 문맥을 활용하여 질문에 답하세요. 모르면 모른다고 말하세요. 세 문장 이내로 간결하게 답변하세요.\n",
      "질문: LangChain이 뭐야?\n",
      "문맥: LangChain은 LLM 앱 개발 프레임워크입니다.\n",
      "답변:\n",
      "\n",
      "=== invoke() 결과 ===\n",
      "messages=[SystemMessage(content='당신은 질문에 답하는 AI 비서입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='아래 제공된 문맥을 활용하여 질문에 답하세요. 모르면 모른다고 말하세요. 세 문장 이내로 간결하게 답변하세요.\\n질문: LangChain이 뭐야?\\n문맥: LangChain은 LLM 앱 개발 프레임워크입니다.\\n답변:', additional_kwargs={}, response_metadata={})]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사용 예시 1: format() - 문자열로 반환\n",
    "example1 = chat_prompt.format(\n",
    "    context=\"LangChain은 LLM 앱 개발 프레임워크입니다.\", \n",
    "    question=\"LangChain이 뭐야?\"\n",
    ")\n",
    "print(\"=== format() 결과 ===\")\n",
    "print(example1)\n",
    "print()\n",
    "\n",
    "# 사용 예시 2: invoke() - Runnable 로 반환\n",
    "example2 = chat_prompt.invoke({\n",
    "    \"context\": \"LangChain은 LLM 앱 개발 프레임워크입니다.\",\n",
    "    \"question\": \"LangChain이 뭐야?\"\n",
    "})\n",
    "print(\"=== invoke() 결과 ===\")\n",
    "print(example2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfe84d-cc19-4227-bee4-56b69508ab11",
   "metadata": {
    "id": "77dfe84d-cc19-4227-bee4-56b69508ab11"
   },
   "source": [
    "### **LangGraph**를 사용하여 **검색(Retrieval)** 과 **생성(Generation)** 단계를 하나의 애플리케이션으로 통합 \n",
    "\n",
    "1. **입력 질문(question)**  \n",
    "2. **검색된 문맥(retrieved context)**  \n",
    "3. **생성된 답변(generated answer)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7bab225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# 애플리케이션의 상태(State) 객체 정의\n",
    "class State(TypedDict):\n",
    "    question: str          # 사용자 질문을 저장하는 문자열 필드\n",
    "    context: List[Document]    # 검색된 문서 목록을 저장하는 필드\n",
    "    answer: str           # 생성된 답변을 저장하는 문자열 필드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77868d9a-892f-4b2c-b706-850f96b4464f",
   "metadata": {
    "id": "77868d9a-892f-4b2c-b706-850f96b4464f"
   },
   "source": [
    "#### **노드 (애플리케이션 단계)**\n",
    "\n",
    "간단한 두 단계로 구성된 시퀀스를 정의해 보겠습니다:  \n",
    "\n",
    "1. **검색 (Retrieval)**  \n",
    "2. **생성 (Generation)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121cb602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자의 질문을 기반으로 벡터 스토어에서 관련 문서를 검색\n",
    "def retrieve(state: State):\n",
    "    # 벡터 스토어에서 질문과 유사도가 높은 문서를 검색\n",
    "    retrieved_docs = vector_store.similarity_search(state['question'])\n",
    "    return {\"context\": retrieved_docs}  #artifact 반환\n",
    "    \n",
    "# 검색된 문서와 질문을 기반으로 모델이 답변을 생성\n",
    "def generate(state: State):\n",
    "    # 검색된 문서(context) 내용을 하나의 문자열로 합칩니다. -> 직렬화\n",
    "    combined_context = \"\\n\\n\".join(doc.page_content for doc in state['context'])\n",
    "    \n",
    "    # 프롬프트에 질문과 직렬화된 문서 내용을 전달하여 메시지 생성\n",
    "    messages = chat_prompt.invoke({\"context\": combined_context, \"question\": state[\"question\"]})\n",
    "    response = model.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac9dc3-d73d-48c3-be05-4b60e0b8bc17",
   "metadata": {
    "id": "d1ac9dc3-d73d-48c3-be05-4b60e0b8bc17"
   },
   "source": [
    "애플리케이션을 하나의 **`graph` 객체**로 컴파일합니다.  여기서는 **검색 단계**와 **생성 단계**를 **단일 시퀀스(sequence)** 로 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61d8eb0f-2045-45b8-b09f-5e9d1c558d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x10d922c10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# StateGraph 초기화\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 검색(retrieve)과 생성(generate) 단계를 순차적으로 실행하도록 설정 (node 자동 추가)\n",
    "workflow.add_sequence([retrieve, generate])\n",
    "\n",
    "# 그래프의 시작점(START)을 'retrieve' 단계와 연결\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "\n",
    "# 그래프를 컴파일하여 최종 그래프 객체를 생성\n",
    "app = workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "768c7af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: LLM 에이전트의 4가지 유형은 무엇인가요?\n",
      "\n",
      "\n",
      "Context: {'source': 'https://botpress.com/ko/blog/llm-agents', 'start_index': 2397}\n",
      "\n",
      "\n",
      "Answer: LLM 에이전트의 4가지 유형은 대화형 상담원, 작업 지향 에이전트, 크리에이티브 에이전트, 협업 에이전트입니다.  \n",
      "대화형 상담원은 사용자와 자연스러운 대화를 통해 정보를 제공하고 문제를 해결합니다.  \n",
      "작업 지향 에이전트는 특정 작업 수행에 집중하고, 크리에이티브 에이전트는 창의적 콘텐츠를 제작하며, 협업 에이전트는 인간과의 협업을 촉진합니다.\n"
     ]
    }
   ],
   "source": [
    "# 그래프를 호출하여 사용자 질문에 대한 답변을 생성\n",
    "result = app.invoke({\"question\": \"LLM 에이전트의 4가지 유형은 무엇인가요?\"})\n",
    "\n",
    "# 질문\n",
    "print(f'Question: {result[\"question\"]}\\n\\n')\n",
    "\n",
    "# 문서의 출처\n",
    "print(f'Context: {result[\"context\"][0].metadata}\\n\\n')\n",
    "\n",
    "# 생성된 답변(Answer)을 출력\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tjC2SdXftfcz",
   "metadata": {
    "id": "tjC2SdXftfcz"
   },
   "source": [
    "-----------------\n",
    "**LangGraph**는 RAG 애플리케이션을 구축하는 데 반드시 필요하지는 않습니다. 실제로 개별 구성 요소를 사용하여 동일한 애플리케이션 로직을 구현할 수도 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a062bcfe-615b-46cd-a4f4-3b87887ff911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 에이전트의 4가지 유형은 1) 대화형 상담원, 2) 작업 지향 에이전트, 3) 크리에이티브 에이전트, 4) 협업 에이전트입니다.\n"
     ]
    }
   ],
   "source": [
    "# Langgraph 없이 RAG 구현한 경우\n",
    "question = \"LLM 에이전트의 4가지 유형은 무엇인가요?\"\n",
    "\n",
    "# 벡터 스토어에서 질문과 유사한 문서 검색\n",
    "retrieved_docs = vector_store.similarity_search(question)\n",
    "\n",
    "# 검색된 문서들의 내용을 하나의 문자열로 결합\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "# 검색된 문서(Context)와 질문을 프롬프트 템플릿에 전달하여 메시지 생성\n",
    "message = chat_prompt.invoke({\"question\": question, \"context\": docs_content}).to_messages()\n",
    "\n",
    "# LLM(대형 언어 모델)을 호출하여 답변 생성\n",
    "answer = model.invoke(message)\n",
    "\n",
    "# 생성된 답변 출력\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924876e-6320-4ef4-a4cd-04ea707cb004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
