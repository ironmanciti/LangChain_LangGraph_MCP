{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23be82a2",
   "metadata": {},
   "source": [
    "# 기본 Chatbot 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eedb549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API-KEY 읽어오기\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27665d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 모델 초기화\n",
    "llm = init_chat_model(\"openai:gpt-5-nano\")\n",
    "# llm = init_chat_model(\"google_genai:gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930b61c-cd0c-4e2d-89e0-7490d3a782b7",
   "metadata": {},
   "source": [
    "### 상태는 워크플로우에서 노드 간 데이터를 전달하는 데 사용\n",
    "\n",
    "```\n",
    "messages: Annotated[list, add_messages]\n",
    "```\n",
    "실제 타입은 list이고, add_messages는 메시지 병합(리듀스) 전략이라는 메타데이터입니다. LangGraph가 이 메타데이터를 읽어 messages를 누적/병합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e840d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# 에이전트의 상태 정의 클래스\n",
    "class State(TypedDict):\n",
    "    # Annotated: 타입 힌트\n",
    "    # add_messages: 상태 업데이트 시 메시지를 덮어쓰지 않고 추가\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 상태 기반 워크플로우 생성\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f6833a",
   "metadata": {},
   "source": [
    "### 노드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fcaf755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1162ee410>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 챗봇 노드 함수\n",
    "def chatbot(state: State):\n",
    "    # LLM의 출력(응답)을 messages 리스트에 추가하여 반환\n",
    "    result = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "\n",
    "# 워크플로우에 chatbot 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abab0d0",
   "metadata": {},
   "source": [
    "### entry point 추가 및 compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd20b06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x1162f4590>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 워크플로우의 시작점(START)에서 'chatbot' 노드로 이동하는 엣지 추가\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "# 'chatbot' 노드에서 워크플로우의 종료점(END)로 이동하는 엣지 추가\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "# 워크플로우 컴파일, 실행 가능한 워크플로우 생성\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65aa16e",
   "metadata": {},
   "source": [
    "### chatbot 실행\n",
    "  \n",
    "| 구분                                   | 실행 시점            | 반환 시점                       | 반환 내용                     | 사용 목적                         |\n",
    "| ------------------------------------ | ---------------- | --------------------------- | ------------------------- | ----------------------------- |\n",
    "| `invoke()`                           | 전체 그래프 한 번 실행    | **모든 노드가 끝난 뒤 한 번만 반환**     | 최종 state (모든 messages 포함) | 결과만 필요할 때                     |\n",
    "| `stream(..., stream_mode=\"updates\")` | 그래프 각 노드 실행마다 반환 | **각 노드 종료 시마다 변경된 부분만 반환**  | 추가된 messages, 변경분(delta)  | 실시간 업데이트/로그용 (가장 효율적)         |\n",
    "| `stream(..., stream_mode=\"values\")`  | 그래프 각 노드 실행마다 반환 | **각 노드 종료 시마다 전체 state 반환** | 누적된 전체 messages           | 단계별 전체 흐름 보기 (values 기반 스트리밍) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a4ba18-3753-4f5a-afa0-ee83df083018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='LangGraph와 LangChain의 차이점에 대해 짧게 설명해줘', additional_kwargs={}, response_metadata={}, id='c5875f04-f737-4f33-8eca-d628204ed29e'),\n",
       "  AIMessage(content='짧은 차이점 요약:\\n\\n- LangChain\\n  - 정의: LLM 앱 구축에 쓰이는 널리 쓰이는 프레임워크. 체인(chains), 에이전트(agents), 도구(tools), 메모리(memory) 등을 중심으로 설계.\\n  - 흐름: 주로 순차적이거나 에이전트 중심의 흐름을 표준화된 컴포넌트로 구성.\\n  - 생태계: 문서와 플러그인/통합이 풍부하고, Python과 JavaScript 등 多언어 지원이 잘 되어 있음.\\n  - 용도: 빠른 프로토타이핑, 다양한 도구/서비스 연결, 일반적인 LLM 응용에 적합.\\n\\n- LangGraph\\n  - 정의: 그래프 기반의 LLM 워크플로우 오케스트레이션 프레임워크. 노드-엣지 그래프를 통해 태스크와 데이터 흐름을 명시적으로 표현.\\n  - 흐름: 노드 간 의존성, 조건부 흐름, 병렬성 등 데이터 흐름을 그래프로 직접 모델링.\\n  - 특징: 재현성과 디버깅에 유리하고, 복잡한 비선형 워크플로우를 관리하기에 적합.\\n  - 용도: 그래프 중심의 모듈식 워크플로우를 설계하고 재사용하려는 경우에 강점.\\n\\n간단히 말해, LangChain은 체인/에이전트 중심의 넓은 생태계와 빠른 개발에 적합한 반면, LangGraph는 그래프 기반으로 복잡한 의존성과 데이터 흐름을 명시적으로 다루는 워크플로우에 초점을 둡니다. 필요에 따라 두 도구를 함께 쓰기도 좋습니다. 더 자세한 비교나 예제가 필요하면 말해줘.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1756, 'prompt_tokens': 23, 'total_tokens': 1779, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1344, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNSeerWseJSH7BfhARRS8Ge2hns3U', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--74096952-01fa-4ee6-8549-e96b13082419-0', usage_metadata={'input_tokens': 23, 'output_tokens': 1756, 'total_tokens': 1779, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1344}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"LangGraph와 LangChain의 차이점에 대해 짧게 설명해줘\"\n",
    "# 그래프를 invoke 모드로 실행\n",
    "result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c7cac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content='짧게 요약하면:\\n\\n- LangChain: LLM 애플리케이션을 체인(또는 에이전트) 방식으로 구성하는 프레임워크. 프롬프트 템플릿, 체인/에이전트 관리, 도구 연결, 메모리 등 광범위한 기능을 제공하고 생태계가 매우 큽니다.\\n- LangGraph: 이름이 같은 다른 프로젝트일 가능성이 있어 정확한 차이를 말하려면 어느 것을 가리키는지 확인이 필요합니다. 일반적으로 “그래프(노드/엣지) 기반의 추론이나 의사결정”에 초점을 둔 도구일 수 있습니다. 즉, 그래프 표현으로 지식 연결이나 다단계 추론을 다루는 방향일 가능성이 있습니다.\\n\\n정확한 비교를 위해:\\n- 어떤 LangGraph 레포트 가리키는지 링크를 보내주시면, 그 구현과 LangChain의 특정 버전과의 차이를 구체적으로 짚어 드리겠습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1701, 'prompt_tokens': 23, 'total_tokens': 1724, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1472, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNSepqmVn4sbRyKh4SeslF2XnwrDK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a615bbac-e220-4423-bc3b-2b1b87a5a460-0', usage_metadata={'input_tokens': 23, 'output_tokens': 1701, 'total_tokens': 1724, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1472}})]}}\n"
     ]
    }
   ],
   "source": [
    "user_input = \"LangGraph와 LangChain의 차이점에 대해 짧게 설명해줘\"\n",
    "# 그래프를 스트리밍 모드로 실행\n",
    "events = graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, stream_mode=\"updates\")\n",
    "for event in events:  \n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9ce0a39-8d61-425c-9066-157d58ae5d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='LangGraph와 LangChain의 차이점에 대해 짧게 설명해줘', additional_kwargs={}, response_metadata={}, id='fa31a26c-99f6-4ec5-b967-c46aa956ed55')]}\n",
      "{'messages': [HumanMessage(content='LangGraph와 LangChain의 차이점에 대해 짧게 설명해줘', additional_kwargs={}, response_metadata={}, id='fa31a26c-99f6-4ec5-b967-c46aa956ed55'), AIMessage(content='짧게 비교하면 다음과 같습니다.\\n\\n- 목적\\n  - LangChain: LLM 애플리케이션을 쉽게 구축하도록 프롬프트, 도구, 메모리, 에이전트 등을 조합하는 라이브러리.\\n  - LangGraph: LLM 워크플로를 그래프(노드-에지)로 표현하고 실행하는 프레임워크로, 작업 간 의존성 관리에 초점.\\n\\n- 구성 요소\\n  - LangChain: Chains, Agents, Tools, Memory 등 고수준 구성요소 중심.\\n  - LangGraph: 노드/에지 그래프와 DAG 실행 엔진 중심.\\n\\n- 실행 방식\\n  - LangChain: 순차 체인이나 에이전트의 도구 호출 흐름 위주.\\n  - LangGraph: 그래프 의존성에 따라 병렬 실행이나 서브그래프 재사용을 가능하게 하는 DAG 기반 실행.\\n\\n- 생태계/적용 범위\\n  - LangChain: 넓은 생태계와 다수의 LLM/툴 통합으로 다목적 애플리케이션에 적합.\\n  - LangGraph: 그래프 기반 워크플로 관리나 데이터 흐름 파이프라인 같은 복잡한 흐름에 강점이 있을 수 있음.\\n\\n원하시면 두 라이브러리의 공식 문서를 확인해 더 구체적으로 비교해 드릴게요. 어떤 사용 사례를 생각하고 계신가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2049, 'prompt_tokens': 23, 'total_tokens': 2072, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1728, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNSTgx1RIMu501Z5IvCZtuH56AR75', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6f1264ff-f0ce-45ec-a154-43e515fcfe08-0', usage_metadata={'input_tokens': 23, 'output_tokens': 2049, 'total_tokens': 2072, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1728}})]}\n"
     ]
    }
   ],
   "source": [
    "user_input = \"LangGraph와 LangChain의 차이점에 대해 짧게 설명해줘\"\n",
    "# 그래프를 스트리밍 모드로 실행\n",
    "events = graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, stream_mode=\"values\")\n",
    "for event in events:  \n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1cde5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  안녕!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요! 반가워요. 무엇을 도와드릴까요?\n",
      "\n",
      "간단한 대화 연습, 번역, 글쓰기 도움, 정보 검색, 문제 해결 등 어떤 주제든 말씀해 주세요. 원하시는 방식으로 바로 도와드릴게요.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  LangChain이 뭐야\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangChain은 LLM(대형 언어 모델) 기반 애플리케이션을 쉽게 만들 수 있게 도와주는 오픈소스 프레임워크예요. 프롬프트 작성, LLM 호출, 외부 도구 사용, 기억(memory) 관리 등을 체계적으로 구성하는 다양한 구성 요소를 제공합니다.\n",
      "\n",
      "주요 포인트\n",
      "- 프레임워크의 핵심 아이디어: 여러 단계의 “체인(chains)”으로 LLM 호출을 연결하고, 필요하면 외부 도구(API, 검색, 데이터베이스 등)을 호출하게 만듦.\n",
      "- 구성 요소\n",
      "  - LLMs: OpenAI, Cohere, Hugging Face 등의 모델과 쉽게 연결\n",
      "  - Prompts와 PromptTemplate: 질문/지시문을 재사용 가능한 템플릿으로 구성\n",
      "  - Chains: 간단한 순차 체인부터 복잡한 워크플로까지 연결\n",
      "  - Agents와 Tools: 에이전트가 상황에 맞춰 도구를 선택하고 사용\n",
      "  - Memory: 대화 맥락 기억, 대화 상태 유지\n",
      "  - Vector Stores와 Embeddings: 문서 검색(RAG)용 인덱스(예: FAISS, Chroma)\n",
      "  - Document Loaders: PDF, HTML 등 문서를 로드하고 처리\n",
      "- 사용 사례\n",
      "  - 챗봇/대화형 에이전트\n",
      "  - 검색-기반 질의응답(RAG) 시스템\n",
      "  - 문서 요약, 정보 추출\n",
      "  - 외부 API와의 자동화 워크플로우(날씨 조회, 데이터베이스 질의 등)\n",
      "- 설치와 시작\n",
      "  - 설치: pip install langchain\n",
      "  - 기본 흐름 예시: LLM을 불러오고 PromptTemplate로 질문을 만들고 LLMChain으로 실행\n",
      "- 주의점\n",
      "  - 비용 관리: API 사용량에 따른 비용 발생\n",
      "  - 데이터 프라이버시와 보안\n",
      "  - 모델의 한계와 응답 품질 관리\n",
      "\n",
      "간단한 예시 느낌\n",
      "- 간단한 Q&A 체인 구성:\n",
      "  - LLM 인스턴스\n",
      "  - PromptTemplate으로 “질문에 대해 간단하고 명확하게 답하세요: {question}”\n",
      "  - LLMChain에 연결하고 run하면 질문에 대한 답을 얻음\n",
      "\n",
      "필요하시면 한국어로 된 간단한 예제 코드도 같이 제공해 드릴게요. 예를 들어 Python으로 LangChain의 가장 기본적인 체인을 만든다거나, 검색 기반으로 정보를 가져오는 간단한 에이전트를 구성하는 방법을 보여드릴 수 있습니다. 원하는 사용 사례나 현재 사용하려는 언어(Python/JavaScript)도 알려주면 맞춤 예제를 드리겠습니다.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    # 그래프를 스트리밍 모드로 실행\n",
    "    events = graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]})\n",
    "    for event in events:\n",
    "        for value in event.values():\n",
    "            # 최신 메시지(마지막 메시지)의 내용을 출력\n",
    "            value[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")  # 사용자 입력 받기\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:  # 종료 조건\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)  # 워크플로우 실행\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6850d951-b246-4dcb-854d-66f694647ec3",
   "metadata": {},
   "source": [
    "### MemorySaver checkpointer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd15cdc7-150f-43f7-820e-49b42fb8f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# MemorySaver: 워크플로우의 상태를 메모리에 저장\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba886996-f69f-416c-80a6-f64757487e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "# 에이전트의 상태 정의 클래스\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 상태 기반 워크플로우 생성\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 웹 검색을 도구 리스트에 추가\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "# LLM에 도구를 바인딩하여 도구 호출 가능하게 설정\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# chatbot 노드 함수\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 워크플로우에 chatbot 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# LangGraph의 prebuilt ToolNode를 사용\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "# tool 노드 워크플로우에 추가\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# 조건부 라우팅: tools로 이동하거나 END로 이동 (종료)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,  # 마지막 메시지에 `tool_calls`가 있는지 확인                \n",
    ")\n",
    "\n",
    "# tools 노드 실행 후 chatbot 노드로 다시 이동 (도구 결과 처리)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "# 워크플로우 시작점에서 chatbot 노드로 이동\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# memory checkpointer 사용 compile\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "graph;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f86f6c07-c217-4001-9067-54b1809d83a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "               *              \n",
      "               *              \n",
      "               *              \n",
      "          +---------+         \n",
      "          | chatbot |         \n",
      "          +---------+         \n",
      "          .         *         \n",
      "        ..           **       \n",
      "       .               *      \n",
      "+---------+         +-------+ \n",
      "| __end__ |         | tools | \n",
      "+---------+         +-------+ \n"
     ]
    }
   ],
   "source": [
    "# 그래프를 ASCII 아트로 출력\n",
    "print(graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34fc6dea-0413-495e-a863-95540a7ebc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  안녕 나는 길동이야\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "길동님, 반가워요! 저는 여기 있어요. 어떤 걸 도와드릴까요? 예시로 아래 중에서 원하시는 것을 말씀해 주셔도 됩니다.\n",
      "\n",
      "- 한국어 대화 연습이나 문장 다듬기\n",
      "- 글쓰기 아이디어나 글 점검\n",
      "- 정보 찾고 요약해 드리기\n",
      "- 코딩이나 기술 질문 해결\n",
      "- 여행 plan이나 취미 이야기\n",
      "\n",
      "혹시 지금 한국어로 간단한 자기소개를 좀 더 자연스럽게 다듬어 볼까요? 예시도 만들어 드릴 수 있어요.\n",
      "\n",
      "오늘은 어떤 주제로 시작해 볼까요?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  내 이름이 뭐라고?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "당신의 이름은 길동입니다.\n",
      "\n",
      "필요하면 더 자연스럽게 소개하는 문장도 만들어 드릴게요. 몇 가지 예시를 드리면:\n",
      "- 공식/겸손한 톤: 안녕하세요. 제 이름은 길동입니다.\n",
      "- 일상적인 톤: 안녕하세요, 저는 길동이에요.\n",
      "- 친구나 네트워킹: 안녕, 나는 길동이라고 해.\n",
      "\n",
      "원하는 톤이나 상황이 있으면 알려 주세요. 그에 맞춰 다듬어 드릴게요.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# 대화 세션을 구분하기 위한 설정\n",
    "# thread_id는 대화의 고유 식별자로, MemorySaver가 대화 기록을 저장/로드하는 데 사용\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # 워크플로우를 스트리밍 모드로 실행 (사용자 입력 처리)\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config=config\n",
    "    )\n",
    "    for event in events:\n",
    "        for value in event.values():\n",
    "            # 이벤트의 마지막 메시지 출력\n",
    "            value[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"사용자: \")  # 사용자 입력 받기\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:  # 종료 조건\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # 워크플로우 실행\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e34952cd-408b-4c84-816c-f8ba512c8f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  내 이름이 뭐라고?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "내 이름이 뭐라고?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "지금 이 대화에서 당신의 이름을 알 수 없어요. 이름을 알려주시면 그 이름으로 불러드리겠습니다. 원하시는 호칭이 있다면 그것도 말씀해 주세요. 예를 들어 “수민님”이나 “수민”처럼 불러드리면 됩니다. 편하신 방식으로 알려주시면 되어요.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# 새로운 thread_id 사용 (새로운 대화 세션)\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # 워크플로우를 스트리밍 모드로 실행 (사용자 입력 처리)\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config=config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"사용자: \")  # 사용자 입력 받기\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:  # 종료 조건\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # 워크플로우 실행\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3afb1d4-2121-46cd-b365-c5e6416999e4",
   "metadata": {},
   "source": [
    "### state 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba9e8cbb-c866-469a-b562-a9ce3f618327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- messages --------------------\n",
      "content='안녕 나는 길동이야' additional_kwargs={} response_metadata={} id='4716092e-d87d-4643-a92a-8920e72722df'\n",
      "content='길동님, 반가워요! 저는 여기 있어요. 어떤 걸 도와드릴까요? 예시로 아래 중에서 원하시는 것을 말씀해 주셔도 됩니다.\\n\\n- 한국어 대화 연습이나 문장 다듬기\\n- 글쓰기 아이디어나 글 점검\\n- 정보 찾고 요약해 드리기\\n- 코딩이나 기술 질문 해결\\n- 여행 plan이나 취미 이야기\\n\\n혹시 지금 한국어로 간단한 자기소개를 좀 더 자연스럽게 다듬어 볼까요? 예시도 만들어 드릴 수 있어요.\\n\\n오늘은 어떤 주제로 시작해 볼까요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 784, 'prompt_tokens': 1356, 'total_tokens': 2140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 640, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNSgMpLy9kJ3EYmNCmT7t93cZ2DI0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--e022a5cf-00e7-440d-8ffe-a2e95ad2522f-0' usage_metadata={'input_tokens': 1356, 'output_tokens': 784, 'total_tokens': 2140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 640}}\n",
      "content='내 이름이 뭐라고?' additional_kwargs={} response_metadata={} id='048b4eca-95cc-4cc7-9811-47898248e8d2'\n",
      "content='당신의 이름은 길동입니다.\\n\\n필요하면 더 자연스럽게 소개하는 문장도 만들어 드릴게요. 몇 가지 예시를 드리면:\\n- 공식/겸손한 톤: 안녕하세요. 제 이름은 길동입니다.\\n- 일상적인 톤: 안녕하세요, 저는 길동이에요.\\n- 친구나 네트워킹: 안녕, 나는 길동이라고 해.\\n\\n원하는 톤이나 상황이 있으면 알려 주세요. 그에 맞춰 다듬어 드릴게요.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 827, 'prompt_tokens': 1507, 'total_tokens': 2334, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 704, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNSghjErJhEcK8oal1m1OAa34VcKb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f20bebe4-733f-44a1-878c-5a5926df843f-0' usage_metadata={'input_tokens': 1507, 'output_tokens': 827, 'total_tokens': 2334, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 704}}\n",
      "-------------------- config --------------------\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a2453-826b-6652-8004-38464b5b0021'}}\n",
      "-------------------- next --------------------\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# thread_id: 1\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# config에 해당하는 워크플로우의 상태 스냅샷 조회\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "print(\"-\" * 20, \"messages\", \"-\" * 20)\n",
    "for v in snapshot.values['messages']:\n",
    "    print(v)\n",
    "print(\"-\" * 20, \"config\", \"-\" * 20)\n",
    "print(snapshot.config)\n",
    "print(\"-\" * 20, \"next\", \"-\" * 20)\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fffd07af-86fe-46e8-ae42-77fab6426fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- messages --------------------\n",
      "content='내 이름이 뭐라고?' additional_kwargs={} response_metadata={} id='8e4c1b4e-eeed-4e0d-82d9-ae9995e3ff39'\n",
      "content='지금 이 대화에서 당신의 이름을 알 수 없어요. 이름을 알려주시면 그 이름으로 불러드리겠습니다. 원하시는 호칭이 있다면 그것도 말씀해 주세요. 예를 들어 “수민님”이나 “수민”처럼 불러드리면 됩니다. 편하신 방식으로 알려주시면 되어요.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 596, 'prompt_tokens': 1355, 'total_tokens': 1951, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNSh9uizr3qz6uZ4Rp02hzGUSPTmm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--5947c562-6ade-44ab-8ffc-6ab33073e04d-0' usage_metadata={'input_tokens': 1355, 'output_tokens': 596, 'total_tokens': 1951, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}\n",
      "-------------------- config --------------------\n",
      "{'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0a2454-7028-634a-8001-31836f4c3f8d'}}\n",
      "-------------------- next --------------------\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# thread_id: 2\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# config에 해당하는 워크플로우의 상태 스냅샷 조회\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "print(\"-\" * 20, \"messages\", \"-\" * 20)\n",
    "for v in snapshot.values['messages']:\n",
    "    print(v)\n",
    "print(\"-\" * 20, \"config\", \"-\" * 20)\n",
    "print(snapshot.config)\n",
    "print(\"-\" * 20, \"next\", \"-\" * 20)\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697fab3b-09eb-40b6-aa2a-d2dd11bf82e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
